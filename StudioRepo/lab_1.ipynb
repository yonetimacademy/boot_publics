{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Bring your own container to SageMaker Studio\n",
    "\n",
    "In this notebook, you create your own Docker image and build a processing container. You use a **ScriptProcessor** class from the Amazon SageMaker Python SDK to run a scikit-learn preprocessing script within the container. Then, you validate the data processing results that are saved in Amazon Simple Storage Service (Amazon S3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1: Environment setup\n",
    "\n",
    "Install the required libraries and dependencies.\n",
    "\n",
    "You set up an Amazon S3 bucket to store the outputs from the processing job and also get the execution role to run the SageMaker processing job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# add csv visualization and image-build packages\n",
    "%pip install sagemaker-studio-image-build \n",
    "%pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role:  arn:aws:iam::995478082385:role/LabVPC-notebook-role\n",
      "Bucket:  databucket-us-west-2-7611696109606748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/abalone_data.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#install-dependencies\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "sagemaker_logger = logging.getLogger(\"sagemaker\")\n",
    "sagemaker_logger.setLevel(logging.INFO)\n",
    "sagemaker_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "#Execution role to run the SageMaker Processing job\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"SageMaker Execution Role: \", role)\n",
    "\n",
    "#S3 bucket to read the SKLearn processing script and writing processing job outputs\n",
    "s3 = boto3.resource('s3')\n",
    "for buckets in s3.buckets.all():\n",
    "    if 'databucket' in buckets.name:\n",
    "        bucket = buckets.name\n",
    "print(\"Bucket: \", bucket)\n",
    "\n",
    "prefix = 'scripts/data'\n",
    "S3Downloader.download(s3_uri=f\"s3://{bucket}/{prefix}/abalone_data.csv\", local_path= 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2: Create a processing container\n",
    "\n",
    "Define and create a scikit-learn container by using the Dockerfile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2.1: Create a Dockerfile\n",
    "\n",
    "Create a Docker directory and add the Dockerfile that creates the processing container. Because you are creating a scikit-learn container, you install pandas and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
    "\n",
    "RUN pip3 install pandas scikit-learn\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ENTRYPOINT [\"python3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2.2: Build the container image\n",
    "\n",
    "Create a custom container image by using the Amazon SageMaker Studio Image Build command line interface (CLI).\n",
    "\n",
    "By using the Amazon SageMaker Studio Image Build CLI, you can build Amazon SageMaker compatible Docker images directly from your SageMaker Studio environments. Using the Image Build CLI helps save time and increase security because it abstracts the creation of the build environment and requires fewer permissions.\n",
    "\n",
    "Navigate to the directory that contains your Dockerfile and run the sm-docker build command. This command automatically logs build output and returns the **Image URI** of your Docker image. This step takes 2–5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "...................[Container] 2025/04/17 12:05:31.794757 Running on CodeBuild On-demand\n",
      "\n",
      "[Container] 2025/04/17 12:05:31.794798 Waiting for agent ping\n",
      "[Container] 2025/04/17 12:05:32.098044 Waiting for DOWNLOAD_SOURCE\n",
      "[Container] 2025/04/17 12:05:32.279343 Phase is DOWNLOAD_SOURCE\n",
      "[Container] 2025/04/17 12:05:32.314768 CODEBUILD_SRC_DIR=/codebuild/output/src59280434/src\n",
      "[Container] 2025/04/17 12:05:32.315387 YAML location is /codebuild/output/src59280434/src/buildspec.yml\n",
      "[Container] 2025/04/17 12:05:32.317716 Setting HTTP client timeout to higher timeout for S3 source\n",
      "[Container] 2025/04/17 12:05:32.318029 Processing environment variables\n",
      "[Container] 2025/04/17 12:05:32.395302 No runtime version selected in buildspec.\n",
      "[Container] 2025/04/17 12:05:32.415061 Moving to directory /codebuild/output/src59280434/src\n",
      "[Container] 2025/04/17 12:05:32.415128 Cache is not defined in the buildspec\n",
      "[Container] 2025/04/17 12:05:32.454176 Skip cache due to: no paths specified to be cached\n",
      "[Container] 2025/04/17 12:05:32.454508 Registering with agent\n",
      "[Container] 2025/04/17 12:05:32.488617 Phases found in YAML: 3\n",
      "[Container] 2025/04/17 12:05:32.488638  POST_BUILD: 3 commands\n",
      "[Container] 2025/04/17 12:05:32.488644  PRE_BUILD: 9 commands\n",
      "[Container] 2025/04/17 12:05:32.488648  BUILD: 4 commands\n",
      "[Container] 2025/04/17 12:05:32.489046 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "[Container] 2025/04/17 12:05:32.489060 Phase context status code:  Message:\n",
      "[Container] 2025/04/17 12:05:32.559006 Entering phase INSTALL\n",
      "[Container] 2025/04/17 12:05:32.593331 Phase complete: INSTALL State: SUCCEEDED\n",
      "[Container] 2025/04/17 12:05:32.593350 Phase context status code:  Message:\n",
      "[Container] 2025/04/17 12:05:32.636283 Entering phase PRE_BUILD\n",
      "[Container] 2025/04/17 12:05:32.668152 Running command echo Logging in to Amazon ECR...\n",
      "Logging in to Amazon ECR...\n",
      "\n",
      "[Container] 2025/04/17 12:05:32.674726 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:34.079029 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 763104351884)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:34.723579 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 217643126080)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:35.386310 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 727897471807)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:36.039659 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 626614931356)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:36.717610 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 683313688378)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:37.363191 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 520713654638)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:38.015427 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 462105765813)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2025/04/17 12:05:38.643112 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "[Container] 2025/04/17 12:05:38.643154 Phase context status code:  Message:\n",
      "[Container] 2025/04/17 12:05:38.678337 Entering phase BUILD\n",
      "[Container] 2025/04/17 12:05:38.679695 Running command echo Build started on `date`\n",
      "Build started on Thu Apr 17 12:05:38 UTC 2025\n",
      "\n",
      "[Container] 2025/04/17 12:05:38.686533 Running command echo Building the Docker image...\n",
      "Building the Docker image...\n",
      "\n",
      "[Container] 2025/04/17 12:05:38.692516 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
      "Sending build context to Docker daemon  4.096kB\n",
      "Step 1/4 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      "3.10-slim-bullseye: Pulling from docker/library/python\n",
      "b983e127c643: Pulling fs layer\n",
      "fea9b2b33f1d: Pulling fs layer\n",
      "853633ff6b4f: Pulling fs layer\n",
      "14fa44a96362: Pulling fs layer\n",
      "14fa44a96362: Waiting\n",
      "fea9b2b33f1d: Verifying Checksum\n",
      "fea9b2b33f1d: Download complete\n",
      "853633ff6b4f: Verifying Checksum\n",
      "853633ff6b4f: Download complete\n",
      "14fa44a96362: Verifying Checksum\n",
      "14fa44a96362: Download complete\n",
      "b983e127c643: Verifying Checksum\n",
      "b983e127c643: Download complete\n",
      "b983e127c643: Pull complete\n",
      "fea9b2b33f1d: Pull complete\n",
      "853633ff6b4f: Pull complete\n",
      "14fa44a96362: Pull complete\n",
      "Digest: sha256:86feb2df29bff296cad3845e1664a6d0efb795489998dcb8ec2937f4426ab5c3\n",
      "Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> a7dd27d6b770\n",
      "Step 2/4 : RUN pip3 install pandas scikit-learn\n",
      " ---> Running in 9918b457421b\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 118.7 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━ 13.5/13.5 MB 117.5 MB/s eta 0:00:00\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 38.1 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 kB 67.2 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     ━━━━━━━━━━━━���━━━━━━━━━━━━━━━━━━━━━━━━━ 347.8/347.8 kB 50.1 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━━━ 16.4/16.4 MB 103.7 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ━━━━━━━━━━━━━━━���━━━━━━━━━━━━━━━━━━━━━━ 301.8/301.8 kB 84.4 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.6/37.6 MB 64.3 MB/s eta 0:00:00\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, six, numpy, joblib, scipy, python-dateutil, scikit-learn, pandas\n",
      "Successfully installed joblib-1.4.2 numpy-2.2.4 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 scikit-learn-1.6.1 scipy-1.15.2 six-1.17.0 threadpoolctl-3.6.0 tzdata-2025.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 9918b457421b\n",
      " ---> 7d928bd647fa\n",
      "Step 3/4 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in d8b8e836e9c6\n",
      "Removing intermediate container d8b8e836e9c6\n",
      " ---> 9f36455ea5bf\n",
      "Step 4/4 : ENTRYPOINT [\"python3\"]\n",
      " ---> Running in f543c43bfd27\n",
      "Removing intermediate container f543c43bfd27\n",
      " ---> 1a9b3ee6df31\n",
      "Successfully built 1a9b3ee6df31\n",
      "Successfully tagged sagemaker-studio:latest\n",
      "\n",
      "[Container] 2025/04/17 12:06:03.235023 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\n",
      "[Container] 2025/04/17 12:06:03.267488 Phase complete: BUILD State: SUCCEEDED\n",
      "[Container] 2025/04/17 12:06:03.267506 Phase context status code:  Message:\n",
      "[Container] 2025/04/17 12:06:03.298362 Entering phase POST_BUILD\n",
      "[Container] 2025/04/17 12:06:03.299749 Running command echo Build completed on `date`\n",
      "Build completed on Thu Apr 17 12:06:03 UTC 2025\n",
      "\n",
      "[Container] 2025/04/17 12:06:03.306697 Running command echo Pushing the Docker image...\n",
      "Pushing the Docker image...\n",
      "\n",
      "[Container] 2025/04/17 12:06:03.312873 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "The push refers to repository [995478082385.dkr.ecr.us-west-2.amazonaws.com/sagemaker-studio]\n",
      "ea1c1ddf5e26: Preparing\n",
      "763868bb9c49: Preparing\n",
      "82c32f007a42: Preparing\n",
      "0b44bb0ecbfc: Preparing\n",
      "164fe584828e: Preparing\n",
      "82c32f007a42: Layer already exists\n",
      "0b44bb0ecbfc: Layer already exists\n",
      "763868bb9c49: Layer already exists\n",
      "164fe584828e: Pushed\n",
      "ea1c1ddf5e26: Pushed\n",
      "latest: digest: sha256:96ba68cc746ea5c16e1842672122c796ac46a88ac565f22c0ccd70c343d8d69d size: 1372\n",
      "\n",
      "[Container] 2025/04/17 12:06:21.690358 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "[Container] 2025/04/17 12:06:21.690377 Phase context status code:  Message:\n",
      "[Container] 2025/04/17 12:06:21.754470 Set report auto-discover timeout to 5 seconds\n",
      "[Container] 2025/04/17 12:06:21.759649 Expanding base directory path:  .\n",
      "[Container] 2025/04/17 12:06:21.761366 Assembling file list\n",
      "[Container] 2025/04/17 12:06:21.761377 Expanding .\n",
      "[Container] 2025/04/17 12:06:21.764571 Expanding file paths for base directory .\n",
      "[Container] 2025/04/17 12:06:21.764582 Assembling file list\n",
      "[Container] 2025/04/17 12:06:21.764585 Expanding **/*\n",
      "[Container] 2025/04/17 12:06:21.772972 No matching auto-discover report paths found\n",
      "[Container] 2025/04/17 12:06:21.773022 Report auto-discover file discovery took 0.018552 seconds\n",
      "[Container] 2025/04/17 12:06:21.773039 Phase complete: UPLOAD_ARTIFACTS State: SUCCEEDED\n",
      "[Container] 2025/04/17 12:06:21.773045 Phase context status code:  Message:\n",
      "\n",
      "Image URI: 995478082385.dkr.ecr.us-west-2.amazonaws.com/sagemaker-studio:latest\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "sudo rm /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n",
    "\n",
    "sudo cp /opt/conda/lib/libstdc++.so.6 /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n",
    "\n",
    "cd docker\n",
    "\n",
    "sm-docker build ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the cell completes, an Image URI is returned that looks like *012345678910.dkr.ecr.us-east-1.amazonaws.com/sagemaker-studio-d-vcbyjgmmjzzy:data-scientist-test-user*.\n",
    "\n",
    "1. Copy the **Image URI** and paste it into a text editor of your choice. \n",
    "\n",
    "You use this **Image URI** to create a **ScriptProcessor** class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3: Run the SageMaker processing job\n",
    "\n",
    "AnyCompany Consulting is working on a project with a wildlife group that is studying abalone age. An abalone is a type of mollusk or marine snail. They want to predict the age of live specimens instead of having to cut open their shells to determine their age.\n",
    "\n",
    "The abalone dataset represents a population of over 4000 abalones. The dataset includes columns for sex, length, diameter, height, whole weight, shucked weight, viscera weight, shell weight, and rings.\n",
    "\n",
    "Run a processing job on the abalone dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>I</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.183</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>F</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.382</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.397</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>I</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.033</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>I</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.165</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>I</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  length  diameter  height  whole_weight  shucked_weight  \\\n",
       "1631   I   0.570     0.445   0.145         0.741           0.306   \n",
       "1740   F   0.675     0.510   0.195         1.382           0.605   \n",
       "2038   I   0.280     0.215   0.080         0.132           0.072   \n",
       "1768   I   0.435     0.300   0.120         0.597           0.259   \n",
       "227    I   0.365     0.270   0.085         0.205           0.078   \n",
       "\n",
       "      viscera_weight  shell_weight  rings  \n",
       "1631           0.172         0.183     12  \n",
       "1740           0.318         0.397     10  \n",
       "2038           0.022         0.033      5  \n",
       "1768           0.139         0.165      8  \n",
       "227            0.049         0.070      7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import-data\n",
    "shape=pd.read_csv(\"data/abalone_data.csv\", header=0)\n",
    "shape.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the SageMaker ScriptProcessor class to define and run a processing script as a processing job. Refer to [SageMaker ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor) for more information about this class.\n",
    "\n",
    "For creating the ScriptProcessor class, you configure the following parameters:\n",
    "- **base_job_name**: Prefix for the processing job name\n",
    "- **command**: Command to run, in addition to any command-line flags\n",
    "- **image_uri**: URI of the Docker image to use for the processing jobs\n",
    "- **role**: SageMaker execution role\n",
    "- **instance_count**: Number of instances to run the processing job\n",
    "- **instance_type**: Type of Amazon Elastic Compute Cloud (Amazon EC2) instance that is used for the processing job\n",
    "\n",
    "1. In the following code, replace **REPLACE_IMAGE_URI** with the URI from your text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker-script-processor\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "# create a ScriptProcessor\n",
    "script_processor = ScriptProcessor(\n",
    "    base_job_name=\"own-processing-container\",\n",
    "    command=[\"python3\"],\n",
    "    image_uri=\"REPLACE_IMAGE_URI\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the ScriptProcessor.run() method to run the **sklearn_preprocessing.py** script as a processing job. Refer to [ScriptProcessor.run()](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor.run) for more information about this method.\n",
    "\n",
    "For running the processing job, you configure the following parameters:\n",
    "- **code**: Path of the preprocessing script \n",
    "- **inputs**: Path of input data for the preprocessing script (Amazon S3 input location)\n",
    "- **outputs**: Path of output for the preprocessing script (Amazon S3 output location)\n",
    "- **arguments**: Command-line arguments to the preprocessing script (such as train test split ratio)\n",
    "\n",
    "The processing job takes approximately 4–5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating processing-job with name own-processing-container-2025-04-17-12-10-57-739\n",
      "Creating processing-job with name own-processing-container-2025-04-17-12-10-57-739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 12:10:57] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating processing-job with name                                      <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#1575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         own-processing-container-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-17-12-10-57-739                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 12:10:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating processing-job with name                                      \u001b]8;id=913398;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=771214;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#1575\u001b\\\u001b[2m1575\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         own-processing-container-\u001b[1;36m2025\u001b[0m-04-17-12-10-57-739                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\n",
      "..{'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://databucket-us-west-2-7611696109606748/scripts/data/abalone_data.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://databucket-us-west-2-7611696109606748/scripts/smstudiofiles/sklearn_preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://databucket-us-west-2-7611696109606748/scripts/data/output/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://databucket-us-west-2-7611696109606748/scripts/data/output/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}]}, 'ProcessingJobName': 'own-processing-container-2025-04-17-12-10-57-739', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '995478082385.dkr.ecr.us-west-2.amazonaws.com/sagemaker-studio:latest', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/sklearn_preprocessing.py'], 'ContainerArguments': ['--train-test-split-ratio', '0.2']}, 'RoleArn': 'arn:aws:iam::995478082385:role/LabVPC-notebook-role', 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:995478082385:processing-job/own-processing-container-2025-04-17-12-10-57-739', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2025, 4, 17, 12, 12, 8, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2025, 4, 17, 12, 11, 35, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2025, 4, 17, 12, 13, 30, 5000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2025, 4, 17, 12, 10, 57, 895000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '2d60c167-d18d-47bb-8021-040547333b6c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2d60c167-d18d-47bb-8021-040547333b6c', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1912', 'date': 'Thu, 17 Apr 2025 12:13:49 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#processing-job\n",
    "import os\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Amazon S3 path prefix\n",
    "input_raw_data_prefix = \"scripts/data\"\n",
    "output_preprocessed_data_prefix = \"scripts/data/output\"\n",
    "scripts_prefix = \"scripts/smstudiofiles\"\n",
    "logs_prefix = \"logs\"\n",
    "\n",
    "# Run the processing job\n",
    "script_processor.run(\n",
    "    code=\"s3://\" + os.path.join(bucket, scripts_prefix, \"sklearn_preprocessing.py\"),\n",
    "    inputs=[ProcessingInput(source=\"s3://\" + os.path.join(bucket, input_raw_data_prefix, \"abalone_data.csv\"),\n",
    "                            destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", \n",
    "                        source=\"/opt/ml/processing/train\",\n",
    "                        destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"train\")),\n",
    "        ProcessingOutput(output_name=\"test_data\", \n",
    "                        source=\"/opt/ml/processing/test\",\n",
    "                        destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"test\")),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.4: Validate the data processing results\n",
    "\n",
    "Validate the output of the processing job that you ran by looking at the first five rows of the train and test output datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows from s3://databucket-us-west-2-7611696109606748/scripts/data/output/train/\n",
      "I,0.18,0.135,0.08,0.033,0.015,0.007,0.01\n",
      "I,0.215,0.15,0.055,0.041,0.015,0.009,0.013\n",
      "M,0.66,0.53,0.17,1.391,0.591,0.212,0.453\n",
      "M,0.715,0.525,0.2,1.89,0.95,0.436,0.431\n",
      "M,0.595,0.455,0.155,1.041,0.416,0.211,0.365\n"
     ]
    }
   ],
   "source": [
    "#view-train-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/train/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/train/train_features.csv - | head -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows from s3://databucket-us-west-2-7611696109606748/scripts/data/output/validation/\n",
      "M,0.55,0.425,0.155,0.918,0.278,0.243,0.335\n",
      "I,0.5,0.4,0.12,0.616,0.261,0.143,0.194\n",
      "M,0.62,0.48,0.155,1.256,0.527,0.374,0.318\n",
      "I,0.22,0.165,0.055,0.055,0.022,0.012,0.02\n",
      "M,0.645,0.5,0.175,1.511,0.674,0.376,0.378\n"
     ]
    }
   ],
   "source": [
    "#view-validation-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/validation/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/test/test_features.csv - | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the cells complete, responses are returned that look like the following output:\n",
    "\n",
    "```plain\n",
    "Top 5 rows from s3://databucket-us-east-1-xxxxxxx/scripts/data/output/validation/\n",
    "M,0.55,0.425,0.155,0.918,0.278,0.243,0.335\n",
    "I,0.5,0.4,0.12,0.616,0.261,0.143,0.194\n",
    "M,0.62,0.48,0.155,1.256,0.527,0.374,0.318\n",
    "I,0.22,0.165,0.055,0.055,0.022,0.012,0.02\n",
    "M,0.645,0.5,0.175,1.511,0.674,0.376,0.378\n",
    "```\n",
    "\n",
    "The column headers for the abalone dataset are sex (Infant, Male, Female), length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, and rings. The output from the **train/** and **validation/** folders shows the processed data that is stored in your S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have built your own processing container and used SageMaker Processing to run the processing job on that custom container.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
